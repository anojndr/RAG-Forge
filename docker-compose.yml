version: '3.8'

services:
  rag-forge:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8086:8086"
    environment:
      # GOGC=50 is a good default for latency-sensitive APIs.
      # It triggers GC more often, reducing pause times.
      # Profile your app and adjust if needed:
      # - Increase to 80 or 100 if CPU is maxed out.
      # - Decrease to 30 if you have CPU to spare and want to minimize latency.
      - GOGC=50
      # For CPU-bound browser tasks, this should be tuned to the number of available CPU threads.
      # For an 8-thread machine, where we assign 6 threads to this service, a value of 6 is ideal.
      - BROWSER_POOL_SIZE=6
    env_file:
      - .env
    # Pin the Go service to the first 6 CPU threads (0-5).
    # This is a Linux-only feature and gives it dedicated resources.
    cpuset: "0-5"
    depends_on:
      - transcript-service
    command: ["./main"]

  transcript-service:
    build:
      context: ./transcript-service
      dockerfile: Dockerfile
    env_file:
      - .env
    # Pin the Python service to the remaining 2 CPU threads (6-7).
    # This prevents it from contending for CPU with the main Go application.
    # The service is internal, so we don't need to expose the port.
    cpuset: "6-7"

networks:
  default:
    driver: bridge