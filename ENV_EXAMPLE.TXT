# Web Search API for LLMs - Environment Configuration

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Port for the HTTP server (default: 8080)
PORT=8080

# =============================================================================
# SEARCH ENGINE CONFIGURATION
# =============================================================================

# Primary search engine to use (default: searxng)
# Valid values: searxng, serper
MAIN_SEARCH_ENGINE=searxng

# Fallback search engine when primary fails (default: serper)
# Valid values: searxng, serper, or leave empty for no fallback
FALLBACK_SEARCH_ENGINE=serper

# =============================================================================
# SEARXNG CONFIGURATION
# =============================================================================

# URL of your SearxNG instance (default: http://127.0.0.1:18088)
SEARXNG_URL=http://127.0.0.1:18088

# =============================================================================
# SERPER API CONFIGURATION
# =============================================================================

# Serper.dev API key for Google Search API (optional)
# Get your API key at: https://serper.dev/
SERPER_API_KEY=your_serper_api_key_here

# Serper API endpoint URL (default: https://google.serper.dev/search)
SERPER_API_URL=https://google.serper.dev/search

# =============================================================================
# YOUTUBE API CONFIGURATION
# =============================================================================

# YouTube Data API key for metadata and comments (optional)
# Get your API key at: https://console.developers.google.com/
YOUTUBE_API_KEY=your_youtube_api_key_here

# URL for the Python transcript microservice
TRANSCRIPT_SERVICE_URL=http://127.0.0.1:8000

# Order of transcript extraction methods (comma-separated)
# Valid entries: ytapi (youtube-transcript-api), tactiq
# Example prioritizing Tactiq first:
# YOUTUBE_TRANSCRIPT_ORDER=tactiq,ytapi
YOUTUBE_TRANSCRIPT_ORDER=ytapi,tactiq

# =============================================================================
# REDDIT API CONFIGURATION
# =============================================================================

# Reddit API credentials for post extraction (optional)
# Get your credentials at: https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=your_reddit_client_id_here
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here
REDDIT_USER_AGENT=WebSearchApiGo/1.0

# =============================================================================
# TWITTER/X EXTRACTION CONFIGURATION
# =============================================================================

# Twitter/X login credentials for browser automation (required for Twitter/X URLs)
# This is necessary because the public API is heavily restricted.
TWITTER_USERNAME=your_twitter_username_or_email
TWITTER_PASSWORD=your_twitter_password

# =============================================================================
# WEBSHARE PROXY CONFIGURATION (Optional)
# =============================================================================

# Webshare proxy credentials for YouTube Transcript API (optional)
# Can help avoid rate-limiting on transcript extraction.
WEBSHARE_PROXY_USERNAME=your_webshare_username_here
WEBSHARE_PROXY_PASSWORD=your_webshare_password_here

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================

# Cache type to use (default: memory)
# Valid values: memory, redis
CACHE_TYPE=memory

# Redis configuration (only used if CACHE_TYPE is redis)
REDIS_URL=127.0.0.1:6379
REDIS_PASSWORD=
REDIS_DB=0
# Cache expiration settings (e.g., 10m, 1h, 30s)
SEARCH_CACHE_TTL=10m
CONTENT_CACHE_TTL=1h

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
# Number of concurrent I/O-bound workers (for light scraping like webpages, reddit, youtube api)
# This can be high as they are mostly waiting for network.
HTTP_WORKER_POOL_SIZE=1000

# Number of concurrent CPU-bound workers (for JS rendering, Twitter/X)
# Should be close to the number of CPU cores. For 4 cores / 8 threads, 4-8 is a good range.
BROWSER_POOL_SIZE=6